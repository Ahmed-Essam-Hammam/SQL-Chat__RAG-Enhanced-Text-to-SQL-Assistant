# ğŸ—„ï¸ SQL Chat â€” RAG-Enhanced Text-to-SQL Assistant

A conversational interface for querying PostgreSQL databases using natural language. The system translates user questions into validated SQL queries, executes them, and returns human-readable answers â€” enhanced by few-shot examples retrieved via RAG.

---

## ğŸ—‚ Project Structure

```
SQL_C_/
â”œâ”€â”€ app.py                  # Main Streamlit app entry point
â”œâ”€â”€ app_langchain.py        # Alternative LangChain-based app
â”œâ”€â”€ chains.py               # LangChain chain definitions (SQL, answer, table selector)
â”œâ”€â”€ config.py               # LLM setup and environment config
â”œâ”€â”€ database.py             # DB connection, schema extraction, query execution
â”œâ”€â”€ prompts.py              # Prompt templates (SQL gen, answer, table selector)
â”œâ”€â”€ sql_generator.py        # Orchestrates SQL generation with RAG examples
â”œâ”€â”€ sql_validator.py        # SQL safety and syntax validation
â”œâ”€â”€ table_selector.py       # Selects relevant tables for a given question
â”œâ”€â”€ answer_generator.py     # Converts SQL results to natural language answers
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ embeddings.py       # HuggingFace embedding model
â”‚   â”œâ”€â”€ vectorstore.py      # Builds ChromaDB vectorstore from few-shot examples
â”‚   â”œâ”€â”€ retriever.py        # Retrieves relevant few-shot examples for a question
â”‚   â”œâ”€â”€ example_data.json   # Few-shot Q&A SQL examples
â”‚   â””â”€â”€ chroma_store/       # Persisted ChromaDB vector store
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ .env.example
```

---

## âš™ï¸ How It Works

```
User Question
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Table Selector â”‚  â†’ Picks only the relevant tables from the DB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG Retriever  â”‚  â†’ Fetches the 3 most similar few-shot SQL examples
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SQL Generator  â”‚  â†’ LLM generates a PostgreSQL query using schema + examples
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SQL Validator  â”‚  â†’ Blocks dangerous keywords, validates tables & syntax
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query Executor â”‚  â†’ Runs the query against PostgreSQL, returns a DataFrame
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Answer Generatorâ”‚  â†’ LLM converts the data into a natural language response
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone <your-repo-url>
cd SQL_C_
```

### 2. Create and activate a virtual environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure environment variables

Copy `.env.example` to `.env` and fill in your credentials:

```bash
cp .env.example .env
```

```env
CEREBRAS_API_KEY=your_cerebras_api_key_here
DB_URL=postgresql://user:password@host:port/dbname
```

### 5. Build the RAG vectorstore

Run this once to embed the few-shot examples into ChromaDB:

```bash
python rag/vectorstore.py
```

### 6. Run the app

```bash
streamlit run app.py
```

---

## ğŸ§  Few-Shot RAG Enhancement

The system uses a local ChromaDB vector store populated with example question-SQL pairs stored in `rag/example_data.json`:

```json
[
  {
    "question": "How many customers are in Brazil?",
    "sql": "SELECT COUNT(*) FROM \"Customer\" WHERE \"Country\" = 'Brazil';"
  }
]
```

At query time, the 3 most semantically similar examples are retrieved and injected into the SQL generation prompt â€” significantly improving accuracy for domain-specific or complex queries.

To add your own examples, edit `rag/example_data.json` and re-run `python rag/vectorstore.py`.

---

## ğŸ›¡ï¸ SQL Validation

Before any query is executed, it passes through a three-layer validation pipeline:

1. **Forbidden keyword check** â€” blocks `DROP`, `DELETE`, `UPDATE`, `INSERT`, `ALTER`, `TRUNCATE`
2. **Table existence check** â€” verifies all referenced tables exist in the database
3. **Syntax check** â€” runs `EXPLAIN` on the query to catch PostgreSQL syntax errors

---

## ğŸ”§ Configuration

| Variable | Description |
|---|---|
| `CEREBRAS_API_KEY` | API key for Cerebras inference |
| `DB_URL` | PostgreSQL connection string (SQLAlchemy format) |

LLM and embedding settings are in `config.py` and `rag/embeddings.py`.

---

## ğŸ§° Tech Stack

- **[LangChain](https://www.langchain.com/)** â€” Chain orchestration and prompt management
- **[ChromaDB](https://www.trychroma.com/)** â€” Local vector store for few-shot examples
- **[HuggingFace](https://huggingface.co/)** â€” `all-MiniLM-L6-v2` for example embeddings
- **[Cerebras](https://www.cerebras.ai/)** â€” LLM inference (OpenAI-compatible API)
- **[PostgreSQL](https://www.postgresql.org/)** â€” Target database
- **[SQLAlchemy](https://www.sqlalchemy.org/)** â€” Database connection and query execution
- **[Streamlit](https://streamlit.io/)** â€” Web interface

---

## ğŸ“ Notes

- The LLM is instructed to always double-quote PostgreSQL identifiers that contain capital letters to prevent case-folding issues.
- The schema inspector automatically fetches column names, data types, and sample values to give the LLM rich context.
- If no relevant tables are found by the table selector, the full schema is used as a fallback.
